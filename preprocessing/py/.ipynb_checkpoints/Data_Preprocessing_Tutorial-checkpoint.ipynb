{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\uddfc Data Preprocessing Tutorial (Step-by-Step)\n", "This notebook will walk you through data preprocessing using the Titanic dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Import Libraries\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import LabelEncoder, StandardScaler"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 2: Load Sample Dataset\n", "df = sns.load_dataset(\"titanic\")\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 3: Understand the Data\n", "df.info()\n", "df.describe()\n", "df.isnull().sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 4: Drop Irrelevant Columns\n", "df = df.drop(columns=['deck', 'embark_town', 'alive'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 5: Handle Missing Values\n", "df['age'].fillna(df['age'].median(), inplace=True)\n", "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 6: Convert Categorical to Numeric\n", "# Label Encoding for binary features\n", "le = LabelEncoder()\n", "df['sex'] = le.fit_transform(df['sex'])\n", "\n", "# One-Hot Encoding for multi-class features\n", "df = pd.get_dummies(df, columns=['class', 'embarked'], drop_first=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 7: Feature Scaling\n", "scaler = StandardScaler()\n", "numeric_cols = ['age', 'fare']\n", "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 8: Train/Test Split\n", "X = df.drop(columns=['survived'])\n", "y = df['survived']\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Optional: Save Preprocessed Data\n", "X_train.to_csv('X_train.csv', index=False)\n", "y_train.to_csv('y_train.csv', index=False)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}